---
layout: post
title: cgc
date:   2012-03-25 17:21:00
permalink: /research/cgc/
group: research
---

## Description ##
`cgc`  is a prototype tool that generates a sound call graph for the application part of a program without analyzing 
the code of the library. It uses a context-insensitive pointer analysis to create the call graph on-the-fly. 
Although the prototype is implemented in `Datalog` for ease of modification and experimentation, it could be 
transcribed into Java to be embedded into an analysis framework such as 
<a href="http://www.sable.mcgill.ca/soot/" target="_blank">Soot</a> or 
<a href="http://wala.sourceforge.net/" target="_blank">Wala</a>.

More details about `cgc`, its pointer analysis, assumptions, empirical evaluation can be found at my 
<a href="{{ "/resources/pubs/confs/ecoop12.pdf" |  prepend: site.baseurl }}" target="_blank">ECOOP'12 paper</a>.

## Workflow ##
<figure>
	<img width="100%" src="{{ "/resources/images/cgc-workflow.png" |  prepend: site.baseurl }}" alt="cgc workflow"></img>
</figure>

## Call Graph Schema ##
`cgc` can output the generated call graph as a <a href="http://www.gupro.de/GXL/" target="_blank">GXL</a> document or a 
directed <a href="http://www.graphviz.org/content/dot-language" target="_blank">DOT</a> graph file. The `DOT` graph can 
be visualized using <a href="http://www.graphviz.org/" target="_blank">Graphviz</a> or converted by `cgc` to a `PNG` or a 
`PS` file that can be visualized using any document previewer. The call graph `GXL` schema used by `cgc` can be found 
<a href="{{ "/resources/cgc/callgraph.xml" | prepend: site.baseurl }}" target="_blank">here</a>.

## Logic Rules ##
`cgc` pointer analysis is implemented declaratively in `Datalog`. `Datalog` makes it easier to focus on "what" you want
from your analysis rather than focusing on "how" to do it. We used the context-insensitive pointer analysis from the 
<a href="http://doop.program-analysis.org/" target=_blank">Doop</a> framework as our base analysis and modified it, 
greatly in many cases, to fit our requirements. The logic rules for `cgc` can be found 
<a href="{{ "/resources/cgc/logic.zip" | prepend: site.baseurl }}">here</a>. There is a README file in the downloaded 
archive that explains which files are taken as is from Doop, files completely new in `cgc`, and Doop files that are 
used after modifying them.

## Experiment Output ##
The output of the experiments used in the empirical evaluation found in my ECOOP'12 paper can be downloaded 
<a href="http://www.dropbox.com/s/68ia8222cd2jrwe/output.zip" target="_blank">here</a>. The download contains two 
folders, one for the <a href="http://sourceforge.net/projects/dacapobench/files/archive/2006-10-MR2/" target="_blank">DaCapo</a> 
benchmarks and another one for the <a href="http://www.spec.org/jvm98/" target="_blank">SPEC JVM98</a> benchmarks. 
Each benchmark program used has a folder that contains the following:

* &lt;benchmark_name&gt;.stats: a text file that contains all the output from the three tools run for each benchmark 
program (`cgc`, Spark, and Doop). It contains important information like preprocessing time, analysis time, etc.
* callgraph/: a folder that contains all the call graphs generated by the three tools as well as the difference call graphs between them.
* database/: a folder that contains the LogicBlox database used by `cgc` and Doop after the analysis finishes execution.
* reflection.stats: a text file that contains statistical information about the use of reflection in the corresponding benchmark.